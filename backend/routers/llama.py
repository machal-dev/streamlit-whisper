from fastapi import APIRouter
from pydantic import BaseModel
from services.llama_service import generate_text

router = APIRouter()

class PromptRequest(BaseModel):
    prompt: str
    max_new_tokens: int = 64
    temperature: float = 0.7
    do_sample: bool = True

@router.post("/llama/generate")
def llama_generate(req: PromptRequest):
    print("ğŸŸ¦ [API] POST /llama/generate ìš”ì²­ ìˆ˜ì‹ ")
    result = generate_text(req.prompt)
    print("ğŸŸ¢ [API] ì‘ë‹µ ë°˜í™˜ ì¤€ë¹„ ì™„ë£Œ")
    return {"result": result}
